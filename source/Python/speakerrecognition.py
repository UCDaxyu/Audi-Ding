# -*- coding: utf-8 -*-
"""SpeakerRecognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DL-dh1zrQkTrhxCcWg_n2OzGf3Q1I6zW
"""

from google.colab import drive
drive.mount('/content/drive')

### Imports ###
import numpy as np
import scipy.signal as sps
from scipy.io import wavfile
import matplotlib.pyplot as plt
from matplotlib import patches
import pandas as pd
pd.set_option("display.precision",2)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
from IPython.display import Audio

### Variables for Use Later ###
myFrames = {}

### The sound files ###
num_train = 11
samplerate={}
data = {}
for set in range(num_train):
  samplerate[set], data[set] = wavfile.read('/content/drive/MyDrive/Colab Notebooks/EEC 201/Final Project/Training/s'+str(set+1)+'.wav') ### LOOK HERE 1

data[8] = data[8][:,0]
data[9] = data[9][:,0]
data[10] = data[10][:,0]

pre_emphasis = 0.97
# pre-emphasize signal https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html
for set in range(num_train):
  data[set] = np.append(data[set][0], data[set][1:] - pre_emphasis * data[set][:-1])

### Main Program ###

def MELFB_own(data,Frame_Size=0.025,Overlap=0.4,samplerate=12500):
  # It is better to chunk the original signal into frames of smaller length
  # Frame length can be found by multiplying the samplerate by framesize. 
  # Frame size is typically between 0.025 seconds and 0.01 seconds
  # The frame length is rounded to nearest integer
  #Frame_Size = 0.025
  Frame_Length = samplerate*Frame_Size
  Frame_Length = int(round(Frame_Length)) 
  #print(Frame_Length)
  #print('sample rate is: ', samplerate)

  # It is important to have overlap between frames
  # Frame_Step can be found by multiplying the samplerate by framestride
  # Frame Stride is found based on the amount of desired overlap (40-60%)
  # The overlap is rounded to nearest integer
  #Overlap = 0.4
  Frame_Stride = Overlap*Frame_Size
  Frame_Step = Frame_Stride*samplerate
  Frame_Step = int(round(Frame_Step))
  #print(Frame_Step)


  # Determine the number of frames 
  # The number of samples in the original signal divided by the overlaps
  num_frames = int(np.ceil(float(np.absolute(len(data)-Frame_Length))/Frame_Step)) 
  #print('number of frames: ',num_frames)

  # Padding required to separate original signal into equal lengthed chunks 
  pad_signal_length = num_frames * Frame_Step + Frame_Length
  #print('Original signal length was:\n',len(data),'\nNew signal length is:\n',pad_signal_length)
  reqd_zeros = np.zeros((pad_signal_length - len(data)))
  data = np.append(data,reqd_zeros)
  #print('Length of the padded signal is:\n',len(data))

  # Next you want to find the indicies for the frames you have set up
  # There should be 'num_frames' frames with length 'Frame_Length'
  # https://numpy.org/doc/stable/reference/generated/numpy.tile.html useful
  ind1 = np.tile(np.arange(0, Frame_Length), (num_frames, 1)) 
  ind2 = np.tile(np.arange(0, num_frames * Frame_Step, Frame_Step), (Frame_Length, 1)).T
  ind3 = ind1 + ind2
  ind1df = pd.DataFrame(ind1,)
  ind2df = pd.DataFrame(ind2)
  ind3df = pd.DataFrame(ind3)
  #print((ind1df.head(1)))
  #print((ind2df.head(1)))
  #print(ind3df.head(2))


  # Assign frame values at specified indices
  frames = data[ind3.astype(np.int32, copy=False)]


  # Window the framed data (hamming window's generally work well)
  window = sps.hamming(Frame_Length)
  windowed_frames = window*frames


  return(windowed_frames)

WF = {}
for set in range(num_train):
  WF[set] = MELFB_own(data[set])


##### The Test Signal #####
#print('\n\n\n\n\n\n\n\n\nThis is my test speaker')
#test_rate1, test_data1 = wavfile.read('/content/drive/MyDrive/Colab Notebooks/EEC 201/Final Project/Test/s1.wav')
#test_data1 = test_data1/np.max(test_data1)
#test_WF1 = MELFB_own(test_rate1,test_data1)

0.4*0.025*12500

import numpy as np
import scipy.signal as sps
import matplotlib.pyplot as plt
import pandas as pd
pd.set_option('display.max_columns', None)

def MAGPOW(Windowed_Frames,num_FFT=512):
  # Find the magnitude of the one sided FFT
  # Real valued signal so symmetry can be used to find other side
  # Power is 1/number of samples *the square of the signal 
  MAG = np.abs(np.fft.rfft(Windowed_Frames, num_FFT))  # Magnitude of the FFT
  POW = ((1.0 / num_FFT) * ((MAG) ** 2))  # Power Spectrum
  return(MAG,POW)

MAG = {}
POW = {}
for set in range(num_train):
  MAG[set], POW[set] = MAGPOW(WF[set])

### Test Signal
#test_MAG1, test_POW1 = MAGPOW(test_WF1)

import numpy as np
import scipy.signal as sps
import matplotlib.pyplot as plt
import pandas as pd
pd.set_option('display.max_columns', None)

def melBanks(num_filt, f_samp, num_FFT, POW, Low_Freq=0):
  High_Freq = f_samp/2
  melMin = 1127*np.log(1+Low_Freq/700)
  melMax = 1127*np.log(1+High_Freq/700)
  mel_points = np.linspace(melMin,melMax,num_filt+2) # K+2 because the start and end points are excluded. Spacing refers to the mel points (hz to mels)
  hz_points = 700*(np.exp(mel_points/1125)-1)  # Convert Mel to Hz

  bank_index = np.floor((num_FFT + 1)*hz_points/f_samp) 
  filt_bank = np.zeros((num_filt, int(np.floor(num_FFT/2+1)))) # Sets up a zero matrix (number of cols will be == number of banks == num_filt length of col will be numFFT/2+1

  for filter in range(1, num_filt + 1):
    # Set up the key points for the triangle (start, center, end)
    filt_start = int(bank_index[filter - 1])  # Left side of triangle
    filt_center = int(bank_index[filter])  # Peak of triangle   
    filt_end = int(bank_index[filter + 1]) # Right Side of triangle
    # fill in the important points for the triangle
    for point in range(filt_start, filt_center):
        filt_bank[filter - 1, point] = 2*(point - bank_index[filter - 1]) / (bank_index[filter] - bank_index[filter - 1])
    for point in range(filt_center, filt_end):
        filt_bank[filter - 1, point] = 2*(bank_index[filter + 1] - point) / (bank_index[filter + 1] - bank_index[filter])
  
  #print(np.shape(POW))

  filter_banks = np.dot(POW, filt_bank.T)
  #print('shape of filter banks is: ', np.shape(filter_banks))

  filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability
  filter_banks = np.log(filter_banks) 
  return(filt_bank,filter_banks)




num_filt = 20
num_FFT = 512
f_samp = 12500/2
freq = np.linspace(0,f_samp,int(num_FFT/2)+1)

myBanks = {}
for set in range (num_train):
  band_pass, myBanks[set] = melBanks(num_filt=num_filt,f_samp=f_samp,num_FFT=num_FFT,POW=POW[set])

   

fig, ax1 = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
for FB in range(len(band_pass)):
  ax1.plot(freq,band_pass[FB],label='Filter'+str(FB))
ax1.set_title('Band Pass Filter Bank\nMel Scale', weight='bold',fontsize=20,color='black')
ax1.set_xlabel('Frequency \n Hertz',fontsize=15)
ax1.set_ylabel('Magnitude',fontsize=15)
ax1.grid()
ax1.legend()

#### Test Signal ####
#test_band_pass, test_myBank1 = melBanks(num_filt=num_filt,f_samp=f_samp,num_FFT=num_FFT,POW=test_POW1)

from scipy.fft import fft, dct
from matplotlib import cm
from scipy.cluster.vq import whiten

num_ceps = 12
mfcc = {}
for set in range(num_train):
  mfcc[set] = dct(myBanks[set], type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13
  mfcc[set] = whiten(mfcc[set]) ### used from rec
  #print(np.shape(mfcc[set]))
  #for dimension in range(np.shape(mfcc[set])[1]):
    #print(np.shape(mfcc[set][:,dimension]))
    #mfcc[set] = mfcc[set]-np.mean(mfcc[set][:,dimension])


#### If you want color plots of MFCC's
#fig, axs = plt.subplots(nrows=3,ncols=4,figsize=[20,15])
#axs[0,0]
#set = 0

#for row in range(3):
#  for col in range(4):
#    if set < 11:
#      c = axs[row,col].pcolor(mfcc[set])
#      axs[row,col].set_title('MFCC'+str(set), weight='bold',fontsize=20,color='black')
#      fig.colorbar(c , ax = axs[row,col])
#      set += 1

"""Find the centroid

  1. Find centroid
  2. Say it's no bueno
  3. Split the centroid along all dimensions by +/- epsilon
  4. Cluster points around Centroid 1 or 2
    1. Cluster around Centroid 1 or 2
    2. least(d1c1,d1c2) etc.
  3. Find New centroids
    1. Take the mean of all dimensions of points clustered about split C1*
    2. Take the mean of all dimensions of points clustered about split C2*
    3. You now have two centroids


"""

def Cent_Finder(data,M=8,ep=0.01):
  # Find's M number of centroids for a given data set
  cycles = int(np.log2(M))
  C = {}
  temp = {}
  D_cent = {}
  C[str(0)] = np.zeros(np.shape(data)[1])
  D_prime = 15000
  D = 14900
  m=1
  k=1
  ep = 0.01
  L = {}
  for dimension in range(np.shape(data)[1]):
    C[str(0)][dimension] = np.mean(data[:,dimension])
  temp[str(0)] = C[str(0)]

  for cycle in range(cycles):
      


      #This is where the splitting occurs

      check = float(np.abs((D_prime-D)/D))
      while check < ep and int(m) < int(M): # If condition to split is met then split
        for key in range(len(C)):
          C[str(key*2)] = temp[str(key)]*(1+ep) 
          C[str(key*2+1)] = temp[str(key)]*(1-ep)
        for key in range(len(C)): 
          temp[str(key)] = C[str(key)]
        DF_C = pd.DataFrame(C)
      

        
        for centroid in range(np.shape(DF_C)[1]):
          L[str(centroid)] = []


        for frame in range(np.shape(data)[0]):
          index = 0
          test = 1E4
          
          
          for value in range(np.shape(DF_C)[1]):
            if np.abs(np.linalg.norm(data[frame,:]-C[str(value)])) < test: 
              #print('frame ',frame,'goes in dimension',value)
              test = np.abs(np.linalg.norm(data[frame,:]-C[str(value)]))
              index = value 
          L[str(index)].append(data[frame])
        

        for centroid in range(np.shape(DF_C)[1]):
          #print('centroid is: ',centroid)
          D1 = np.array(L[str(centroid)])
          DF1 = pd.DataFrame(L[str(centroid)])
          DF2 = DF1.mean(axis=0)
          D2 = np.array(DF2)
          
          for row in range(np.shape(D1)[0]):
            dist_from_cent = np.linalg.norm(D1[row]-D2)
            D = D+float(dist_from_cent)

          C[str(centroid)] = DF2
        for key in range(len(C)): 
          temp[str(key)] = C[str(key)]
        DF_C = pd.DataFrame(C)
        # Next you must find the distortion 'D'
        D=0
        for centroid in L:
          for row in range(np.shape(L[centroid])[0]):

            D = np.linalg.norm(L[centroid][row]-DF2)+D

        check = float(np.abs((D_prime-D)/D))
        for key in range(len(C)): 
          temp[str(key)] = C[str(key)]
        DF_C = pd.DataFrame(C)
        m=len(C)


      # This is where centroid is adjusted if condition isnt met

      check = float(np.abs((D_prime-D)/D))
      while check > ep and int(m) <= int(M): 
        #print(m)
        D_prime = D


        for centroid in range(len(C)):

          if centroid % 2 == 0:
            C[str(centroid)] = C[str(centroid)]*(1+ep)
          else:
            C[str(centroid)] = C[str(centroid)]*(1-ep) 

        for key in range(len(C)): 
          temp[str(key)] = C[str(key)]
        DF_C = pd.DataFrame(C)
      

        L = {}
        for centroid in range(np.shape(DF_C)[1]):
          L[str(centroid)] = []
          #print('first key for L is: ',centroid)
        #print(pd.DataFrame(C))
        for frame in range(np.shape(data)[0]):
          index = 0
          test = 1E4
          #print(pd.DataFrame(C))
          for centroid in range(np.shape(DF_C)[1]):
            #print('shape of frame: ',np.shape(data[frame,:]))
            #print('shape of C: ',np.shape(C[str(centroid)]))
            if np.abs(np.linalg.norm(data[frame,:]-C[str(centroid)])) < test: 
              test = np.abs(np.linalg.norm(data[frame,:]-C[str(centroid)]))
              index = centroid 
          L[str(index)].append(data[frame])

        


        for centroid in range(np.shape(DF_C)[1]):
          #print('centroid is: ',centroid)
          D1 = np.array(L[str(centroid)])
          DF1 = pd.DataFrame(L[str(centroid)])
          DF2 = DF1.mean(axis=0)
          D2 = np.array(DF2)
          
          for row in range(np.shape(D1)[0]):
            dist_from_cent = np.linalg.norm(D1[row]-D2)
            D = D+float(dist_from_cent)

        
          C[str(centroid)] = DF2

        for key in range(len(C)): 
          temp[str(key)] = C[str(key)]
        DF_C = pd.DataFrame(C)
        # Next you must find the distortion 'D'
        D=0
        for centroid in L:
          for row in range(np.shape(L[centroid])[0]):

            D = np.linalg.norm(L[centroid][row]-DF2)+D

        check = float(np.abs((D_prime-D)/D))
        m=len(C)

  clusters = L
  DF_C2 = np.array(DF_C)
  return(DF_C2,clusters)

code = {}
cluster = {}
for set in range(num_train):
  code[set], cluster[set] = Cent_Finder(mfcc[set])






fig, axs = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
dimx = np.random.randint(12)
dimy = np.random.randint(12)
speaker = 0 #np.random.randint(len(cluster))
print(pd.DataFrame(code[speaker]))
c = ['r','orange','y','g','lime','b','c','m']
for centroid in cluster[speaker]:
  cluster[speaker][centroid] = np.array(cluster[speaker][centroid])
  axs.scatter(cluster[speaker][centroid][:,dimx],cluster[speaker][centroid][:,dimy],label='Cluster: '+centroid,color=c[int(centroid)])
  


for centroid in range(np.shape(code[speaker])[1]):
  print(np.shape(code[speaker])[1])
  axs.scatter(code[speaker][dimx][centroid],code[speaker][dimy][centroid],s=300,label='codebook centroid: '+str(centroid),marker='^',color=c[int(centroid)])
axs.legend(bbox_to_anchor=(1.05, 1), loc=2, prop={"size":20})
axs.grid()
xl = 'Dimension '+str(dimx)
yl = 'Dimension '+str(dimy)
title = "Clustered Data and Centroids for Speaker"+str(speaker)
axs.set_xlabel(xl,weight='bold',fontsize=15)
axs.set_ylabel(yl,weight='bold',fontsize=15)
axs.set_title(title,weight='bold',fontsize=20)
plt.show()

code[speaker][dimx][centroid]



#### Step 1 ####
SRT = {} # Dictionary of test signal sample rates
DT = {} # Dictionary of test signal data sets
num_test = 11
for set in range(num_test):
  SRT[set], DT[set] = wavfile.read('/content/drive/MyDrive/Colab Notebooks/EEC 201/Final Project/Test/s'+str(set+1)+'.wav') ### LOOK HERE 2
DT[8] = DT[8][:,0] # remove one channel of stereo from test signal 9
DT[9] = DT[9][:,0] # remove one channel of stereo from test signal 10
DT[10] = DT[10][:,0] # remove one channel of stereo from test signal 11
pre_emphasis = 0.97
# pre-emphasize signal https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html
for set in range(num_test):
  DT[set] = np.append(DT[set][0], DT[set][1:] - pre_emphasis * DT[set][:-1])
#### Step 2 ####
WFT = {} # Dictionary of windowed frames for test signals
for set in range(num_test):
  WFT[set] = MELFB_own(DT[set])
#### Step 3 ####
MAGT = {} # Dictionary for magnitudes of test signals for power spectrum
POWT = {} # Dictionary of power spectrums of test signals
for set in range(num_test):
  MAGT[set], POWT[set] = MAGPOW(WFT[set])
#### Step 4 ####
myBanksT = {} # Dictionary of banks for test signals
for set in range (num_test):
  band_pass, myBanksT[set] = melBanks(num_filt=num_filt,f_samp=f_samp,num_FFT=num_FFT,POW=POWT[set])
#### Step 5 ####
num_ceps = 12
mfccT = {} # Dictionary of mfcc's for test signals
for set in range(num_test):
  mfccT[set] = dct(myBanksT[set], type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13
  mfccT[set] = whiten(mfccT[set]) # PROB DELETE THIS
  #print(np.shape(mfcc[set]))
  #for dimension in range(np.shape(mfccT[set])[1]):
    #print(np.shape(mfcc[set][:,dimension]))
    #mfccT[set] = mfccT[set]-np.mean(mfccT[set][:,dimension])
#### Step 6 ####
codeT = {}
clusterT = {}
for set in range(num_test):
  codeT[set], clusterT[set] = Cent_Finder(mfccT[set])



CODE = {} # Set's up a dictionary of codes to compare to
for speaker in code:
  CODE['speaker'+str(speaker+1)] = pd.DataFrame(code[speaker])

L = {}
for speaker in CODE:
  L[speaker] = {}
  for centroid in CODE[speaker]:
    L[speaker][centroid] = []

S = {}
for test_signal in mfccT:
  S[test_signal] = {}
  for speaker in CODE:
    D = 0
    S[test_signal][speaker] = 0
    for frame in range(np.shape(mfccT[test_signal])[0]):
      index = 0
      test = 1E4
      for centroid in CODE[speaker]:
        if np.abs(np.linalg.norm(mfccT[test_signal][frame,:]-CODE[speaker][centroid])) < test: 
          dist_from_cent = np.abs(np.linalg.norm(mfccT[test_signal][frame,:]-CODE[speaker][centroid]))
          test = dist_from_cent
          D = dist_from_cent
          index = centroid # This tells us which centroid point is closest to
      S[test_signal][speaker] = S[test_signal][speaker] + dist_from_cent
    S[test_signal][speaker] = S[test_signal][speaker]/frame 
    #print('The sum of all distnances for test signal: ',test_signal,'compared to ',speaker,'is: ',S[test_signal][speaker])


DFS = pd.DataFrame(S)
print(DFS)

print(DFS)
print(DFS.index)
DFS_visual = 1/DFS
fig, [ax1,ax2] = plt.subplots(nrows=1,ncols=2,figsize=[20,10])


c1 = ax1.pcolor(DFS_visual)
ax1.set_title('Speaker Recognition\nBrighter Means More Likely to be Speaker', weight='bold',fontsize=20,color='black')
ax1.set_xlabel('Test Speakers',weight='bold',fontsize=15,color='black')
ax1.set_ylabel('Training Speakers',weight='bold',fontsize=15,color='black')
fig.colorbar(c1 , ax = ax1)

c2 = ax2.pcolor(DFS)
ax2.set_title('Speaker Recognition\nDarker Means More Likely to be Speaker', weight='bold',fontsize=20,color='black')
ax2.set_xlabel('Test Speakers',weight='bold',fontsize=15,color='black')
ax2.set_ylabel('Training Speakers',weight='bold',fontsize=15,color='black')
#xticks(DFS.columns) 
fig.colorbar(c2 , ax = ax2)
plt.tight_layout()

print(DFS)
print(DFS.index)
DFS_norm = DFS/np.max(DFS)*100
DFS_visual = 1/DFS
DFS_visual_norm = 1/DFS_norm
fig, [ax1,ax2] = plt.subplots(nrows=1,ncols=2,figsize=[20,10])


c1 = ax1.pcolor(DFS_visual_norm)
ax1.set_title('Speaker Recognition\nBrighter Means More Likely to be Speaker', weight='bold',fontsize=20,color='black')
ax1.set_xlabel('Test Speakers',weight='bold',fontsize=15,color='black')
ax1.set_ylabel('Training Speakers',weight='bold',fontsize=15,color='black')
ax1.set_xticks(np.arange(1,np.shape(DFS)[1]+1,1)) 
ax1.set_yticks(np.arange(1,np.shape(DFS)[0]+1,1)) 
fig.colorbar(c1 , ax = ax1)

c2 = ax2.pcolor(DFS_norm)
ax2.set_title('Speaker Recognition\nDarker Means More Likely to be Speaker', weight='bold',fontsize=20,color='black')
ax2.set_xlabel('Test Speakers',weight='bold',fontsize=15,color='black')
ax2.set_ylabel('Training Speakers',weight='bold',fontsize=15,color='black')
ax2.set_xticks(np.arange(1,np.shape(DFS)[1]+1,1)) 
ax2.set_yticks(np.arange(1,np.shape(DFS)[0]+1,1)) 
fig.colorbar(c2 , ax = ax2)
plt.tight_layout()

for speaker in (DFS):
  print(np.min(DFS[speaker]))

#### Test 2 ####

#### Test 2.A #####
t=1/SRT[0]*np.array(range(len(DT[0])))
DT[0] = DT[0]/np.max(DT[0])
fig1, ax = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
ax.plot(t,DT[0],label='Speaker 1')

ax.set_title('Test Speaker 1',weight='bold',size=20,color='black')
ax.set_xlabel('Time\n(Seconds)',weight='bold',size=20,color='black')
ax.grid()

#### Test 2.B #####

N = 12500*0.025
F,T,STFT = sps.stft(DT[0],window='hamming',fs=12500,nperseg=N,noverlap=125)
pspec = np.abs(STFT)**2/N
pspec = pspec/np.max(pspec)
fig2, axs1 = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
print(len(T))
print(max(T))
X = np.max(T)
X = np.linspace(0,len(T),5)
Xlab = np.linspace(0,max(T),5)

Y = np.max(F)
Y = np.linspace(0,len(F),5)
Ylab = np.linspace(0,max(F),5)


c = axs1.pcolor(pspec)
axs1.set_title('Periodogram\nUsing STFT', weight='bold',fontsize=20,color='black')
axs1.set_xticks(X)
axs1.set_xticklabels(Xlab)
axs1.set_yticks(Y)
axs1.set_yticklabels(Ylab)
axs1.set_ylabel('Frequency\n(Hertz)',weight='bold',size=15)
axs1.set_xlabel('Time\n(Seconds)',weight='bold',size=15)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
fig.colorbar(c , ax = axs1)




X = np.max(T)
X = np.linspace(0,np.shape(POWT[0])[0],5)
Xlab = np.linspace(0,max(T),5)

Y = np.max(F)
Y = np.linspace(0,np.shape(POWT[0])[1],5)
Ylab = np.linspace(0,max(F),5)
plt.tight_layout()


fig3, axs2 = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
print(np.shape(POWT[0]))
POWT[0] = np.transpose(POWT[0])
c = axs2.pcolor(POWT[0])
axs2.set_title('Periodogram\nUsing My Own Power Spectral Density', weight='bold',fontsize=20,color='black')
axs2.set_xticks(X)
axs2.set_xticklabels(Xlab)
axs2.set_yticks(Y)
axs2.set_yticklabels(Ylab)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
axs2.set_ylabel('Frequency\n(Hertz)',weight='bold',size=15)
axs2.set_xlabel('Time\n(Seconds)',weight='bold',size=15)
fig.colorbar(c , ax = axs2)
plt.tight_layout()

#### Test 3 ####

fig4, axs4 = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
print(np.shape(myBanksT[0]))
myBanksT[0] = np.transpose(myBanksT[0])
X = np.max(T)
X = np.linspace(0,np.shape(myBanksT[0])[1],5)
Xlab = np.linspace(0,max(T),5)
Y = np.max(F)
Y = np.linspace(0,np.shape(myBanksT[0])[0],5)
c = axs4.pcolor(myBanksT[0])

axs4.set_title('Periodogram\nUsing My Own Power Spectral Density', weight='bold',fontsize=20,color='black')
axs4.set_xticks(X)
axs4.set_xticklabels(Xlab)
axs4.set_yticks(Y)
axs4.set_yticklabels(Ylab)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
axs4.set_ylabel('Frequency\n(Hertz)',weight='bold',size=15)
axs4.set_xlabel('Time\n(Seconds)',weight='bold',size=15)
fig.colorbar(c , ax = axs4)
plt.tight_layout()

#### Test 4 ####

fig5, axs5 = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
print(np.shape(mfccT[0]))
mfccT[0] = np.transpose(mfccT[0])
X = np.max(T)
X = np.linspace(0,np.shape(myBanksT[0])[1],5)
Xlab = np.linspace(0,max(T),5)

c = axs5.pcolor(mfccT[0])

axs5.set_title('Periodogram\nUsing My Own Power Spectral Density', weight='bold',fontsize=20,color='black')
axs5.set_xticks(X)
axs5.set_xticklabels(Xlab)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
axs5.set_ylabel('MFCC Coefficients',weight='bold',size=15)
axs5.set_xlabel('Time\n(Seconds)',weight='bold',size=15)
fig.colorbar(c , ax = axs5)
plt.tight_layout()

#### TEST 6 #### 
#codeT = {}
#clusterT = {}
#for set in range(num_test):
#  codeT[set], clusterT[set] = Cent_Finder(mfccT[set])

speaker = 0
fig6, axs6 = plt.subplots(nrows=1,ncols=1,figsize=[20,10])
for centroid in range(np.shape(code[speaker])[1]):
  axs6.scatter(code[speaker][dimx][centroid],code[speaker][dimy][centroid],s=350,label='Training Signal centroid: '+str(centroid),marker='^',color='r')
  axs6.scatter(codeT[speaker][dimx][centroid],codeT[speaker][dimy][centroid],s=150,label='Test Signal centroid: '+str(centroid),marker='^',color='c')
axs6.legend(bbox_to_anchor=(1.05, 1), loc=2, prop={"size":20})
axs6.grid()

for centroid in cluster[speaker]:
  cluster[speaker][centroid] = np.array(cluster[speaker][centroid])
  clusterT[speaker][centroid] = np.array(clusterT[speaker][centroid])
  axs6.scatter(cluster[speaker][centroid][:,dimx],cluster[speaker][centroid][:,dimy],label='Cluster: '+centroid,color='b',s=350)
  axs6.scatter(clusterT[speaker][centroid][:,dimx],clusterT[speaker][centroid][:,dimy],label='Cluster: '+centroid,color='g',s=150)



xl = 'Dimension '+str(dimx)
yl = 'Dimension '+str(dimy)
title = "Clustered Data and Centroids for Speaker"+str(speaker)
axs6.set_xlabel(xl,weight='bold',fontsize=15)
axs6.set_ylabel(yl,weight='bold',fontsize=15)
axs6.set_title(title,weight='bold',fontsize=20)



plt.show()

print(np.shape(codeT[speaker]))
print(np.shape(code[speaker]))
print(np.shape(cluster[speaker][str(0)]))
print(np.shape(clusterT[speaker][str(0)]))
print(np.shape(clusterT[speaker][str(0)]))

for centroid in range(8):
  print(np.shape(clusterT[speaker][str(centroid)]))

"""## Flow of Events



1.   Input Speech
2.   Feature Extraction
3.   Similarity (multiple possible references)
4.   Maximum Selection
5.   Identification Result


"""